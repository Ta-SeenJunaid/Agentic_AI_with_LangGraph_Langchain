{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7369cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbce7cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: AI\n",
      "\n",
      "Hello, how are you?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Human\n",
      "\n",
      "I'm fine, thanks!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: AI\n",
      "\n",
      "What can I do for you?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Human\n",
      "\n",
      "I need some help with my code.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from pprint import pprint\n",
    "\n",
    "messages = [AIMessage(content=\"Hello, how are you?\", name=\"AI\"),]\n",
    "messages.append(HumanMessage(content=\"I'm fine, thanks!\", name=\"Human\"))\n",
    "messages.append(AIMessage(content=\"What can I do for you?\", name=\"AI\"))\n",
    "messages.append(HumanMessage(content=\"I need some help with my code.\", name=\"Human\"))\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf91c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "result=llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539c9abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 260,\n",
       "  'prompt_tokens': 55,\n",
       "  'total_tokens': 315,\n",
       "  'completion_time': 0.54719262,\n",
       "  'prompt_time': 0.008810657,\n",
       "  'queue_time': 0.085710893,\n",
       "  'total_time': 0.556003277},\n",
       " 'model_name': 'qwen/qwen3-32b',\n",
       " 'system_fingerprint': 'fp_5cf921caa2',\n",
       " 'service_tier': 'on_demand',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e5481c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked for help with their code. Let me think about the best way to respond. First, I should ask them to provide the code they're having trouble with. But maybe I should also ask for more details about the problem they're facing. Are they getting an error message? If so, what's the error? Or are they encountering unexpected behavior?\n",
      "\n",
      "I need to make sure my response is open-ended so they can give as much information as possible. It's important to be clear and friendly. Maybe something like, \"Sure! Please share the code you're working on, along with any error messages or unexpected behavior you're encountering. The more details you provide, the better I can assist you.\"\n",
      "\n",
      "Wait, that's good. It asks for the code, any errors, and invites them to explain the problem. Let me check if I need to mention anything else. Oh, maybe also ask what they've tried so far. But I don't want to make the request too long. Maybe keep it concise as I suggested. Yeah, that should work.\n",
      "</think>\n",
      "\n",
      "Sure! Please share the code you're working on, along with any error messages or unexpected behavior you're encountering. The more details you provide, the better I can assist you. ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "result.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec9ee7",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad171d",
   "metadata": {},
   "source": [
    "Tool has docstring, that's why LLM can get the info whether it need this tool or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bffdefc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Multiplies two integers and returns the result.\n",
    "    \n",
    "    Args:\n",
    "        a (int): The first integer.\n",
    "        b (int): The second integer.\n",
    "    \n",
    "    Returns:\n",
    "        int: The product of the two integers.\n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d4e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "tool_call=llm_with_tools.invoke([HumanMessage(content=\"What is 3 times 4?\", name=\"Human\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd19839a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 4},\n",
       "  'id': 'qb6rmzhtj',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea8b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
